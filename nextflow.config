// Nextflow configuration for QTL2 Pipeline
// Single container approach for r/qtl2 and data manipulation

// Pipeline metadata
manifest {
    name            = 'QTL2_NF'
    author          = 'Dpbudke'
    homePage        = 'https://github.com/Dpbudke/QTL2_NF'
    description     = 'Nextflow pipeline for multiparental mouse QTL analysis using r/qtl2'
    mainScript      = 'main.nf'
    nextflowVersion = '>=23.04.0'
    version         = '1.0.0'
}

// Default parameters
params {
    // Input files (generated from your pre-pipeline RMD)
    phenotype_file     = 'Data/QTL2_NF_meta_pheno_input.csv'
    finalreport_files  = 'Data/*FinalReport.txt'
    genotype_file      = null  // Will be added in future modules
    genetic_map        = null  // Will be added in future modules
    
    // Study configuration
    study_prefix       = 'MyStudy'
    auto_prefix_samples = false  // Set to true if you want automatic sample ID prefixing
    test_mode          = false   // Set to true to process chromosome 19 only (for development)
    
    // Output directory
    outdir             = 'results'
    
    // Process-specific parameters
    // Module 1: Phenotype Processing
    pheno_na_strings   = 'na,NA,N/A,'
    
    // Module 4: QTL Analysis Parameters
    lod_threshold      = 7.0    // LOD threshold for filtering QTLs before permutation testing
    
    // Sample Filtering Parameters (JSON string for flexible subsetting)
    sample_filter      = null   // JSON filter for sample subsetting (e.g., '{"Sex": ["male"], "Diet": ["hc"]}')

    // DO Mixup QC Parameters (optional standalone analysis)
    run_mixup_qc       = false  // Set to true to run DO sample mixup QC analysis

    // Help message
    help               = false
}

// Global work directory
workDir = '/project/do2_projects/DO_Choline/QTL2_NF/nextflow_work'

// Process configuration
process {
    // Default settings for all processes
    shell = ['/bin/bash', '-euo', 'pipefail']
    
    // Single container for all processes
    container = 'dpbudke/qtl2-pipeline:latest'
    
    // SLURM executor for HPC
    executor = 'slurm'
    clusterOptions = '--account=do2_projects --partition=ceres'
    
    // Resource defaults
    cpus   = 2
    memory = '4 GB'
    time   = '2h'
    
    // Error handling
    errorStrategy = 'retry'
    maxRetries    = 2
    
    // Process-specific overrides
    withName: PHENOTYPE_PROCESS {
        cpus   = 1
        memory = '2 GB'
        time   = '1h'
    }
    
    // Module 2: Genotype processing (64GB for full dataset)
    withName: GENOTYPE_PROCESS {
        cpus   = 2
        memory = '64 GB'
        time   = '4h'
    }
    
    // Module 5: Parallel genome scan preparation
    withName: PREPARE_GENOME_SCAN_SETUP {
        cpus   = 128
        memory = '128 GB'
        time   = '4h'
    }

    withName: PREPARE_GENOME_SCAN_CHR_KINSHIP {
        cpus   = 4
        memory = '16 GB'
        time   = '1h'
    }

    withName: COMBINE_GENOME_SCAN_PREP {
        cpus   = 4
        memory = '16 GB'
        time   = '1h'
    }
    
    // Module 6: Phenotype-chunked genome scanning (priority-mem partition)
    withName: GENOME_SCAN_SETUP {
        cpus   = 4
        memory = '32 GB'
        time   = '1h'
    }

    withName: GENOME_SCAN_BATCH {
        cpus   = 48      // Optimized for batch processing (10 chunks per batch)
        memory = '1.6 TB'  // 1.6TB per batch, ~8 batches in parallel (13TB total limit)
        time   = '12h'   // Time allowance for batch processing
        clusterOptions = '--account=do2_projects --partition=ceres'
        // Parallel batch submission reduces infrastructure exposure
    }

    withName: COMBINE_BATCH_RESULTS {
        cpus   = 16
        memory = '256 GB'
        time   = '2h'
        clusterOptions = '--account=do2_projects --partition=ceres'
    }
    
    // Module 7: Permutation testing (batched approach)
    withName: PERMUTATION_SETUP {
        cpus   = 4
        memory = '32 GB'
        time   = '1h'
    }

    withName: PERMUTATION_BATCH {
        cpus   = 48      // Optimized for permutation batch processing (10 chunks per batch)
        memory = '1.6 TB'  // 1.6TB per batch, ~8 batches in parallel (13TB total limit)
        time   = '12h'   // Time allowance for permutation batch processing
        clusterOptions = '--account=do2_projects --partition=ceres'
        // Parallel batch submission for optimal permutation throughput
    }

    withName: COMBINE_PERMUTATION_RESULTS {
        cpus   = 16
        memory = '256 GB'
        time   = '2h'
        clusterOptions = '--account=do2_projects --partition=ceres'
    }

    // Module 8: Significant QTL identification
    withName: IDENTIFY_SIGNIFICANT_QTLS {
        cpus   = 8
        memory = '64 GB'
        time   = '4h'
    }

    // Module 6: DO Mixup QC (optional standalone analysis)
    withName: DO_MIXUP_QC {
        cpus   = 4
        memory = '32 GB'
        time   = '4h'
    }
}

// Execution profiles
profiles {
    
    // HPC/Ceres execution (default)
    standard {
        process.executor = 'slurm'
        apptainer.enabled = true
        apptainer.autoMounts = true
        apptainer.cacheDir = '/project/do2_projects/DO_Choline/QTL2_NF/singularity_cache'

        executor {
            name = 'slurm'
            pollInterval = '30 sec'        // Check job status every 30 seconds (default is 1min)
            queueStatInterval = '5 min'    // Update queue stats every 5 minutes (default is 1min)
            // submitRateLimit = '50/1min'    // Limit job submission rate - REMOVED to see all submissions
            exitReadTimeout = '90 sec'     // Timeout for reading exit code (default is 90sec)
            killBatchSize = 100            // Batch size for killing jobs
            perJobMemLimit = true          // Enable per-job memory limits
        }
    }
    
    // Local execution 
    local {
        process.executor = 'local'
        docker.enabled = true
        docker.runOptions = '-u $(id -u):$(id -g)'
    }
    
    // Docker profile (for local development)
    docker {
        process.executor = 'local'
        docker.enabled = true
        docker.runOptions = '-u $(id -g):$(id -g)'
    }
    
    // Development/testing profile
    test {
        params.phenotype_file = 'test_data/small_phenotypes.csv'
        params.study_prefix = 'Test'
        params.outdir = 'test_results'
        params.test_mode = true  // Process only chr 19
        
        process {
            cpus = 1
            memory = '2 GB'
            time = '1h'
        }
    }
}

// Reporting and monitoring
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline.html"
    overwrite = true
}

report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report.html"
    overwrite = true
}

trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace.txt"
    overwrite = true
}

dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag.svg"
    overwrite = true
}

// Cleanup options
cleanup = false  // Set to true in production

// Apptainer settings (primary for HPC)
apptainer {
    enabled = false  // Will be enabled by profile
    autoMounts = true
    cacheDir = '/project/do2_projects/DO_Choline/QTL2_NF/singularity_cache'
}

// Singularity settings (disabled, keeping for compatibility)
singularity {
    enabled = false
    autoMounts = true
    cacheDir = '/project/do2_projects/DO_Choline/QTL2_NF/singularity_cache'
}

// Docker settings (for local development)
docker {
    enabled = false  // Will be enabled by profile
    temp = 'auto'
}

// Resource monitoring
monitor {
    enabled = false  // Enable for detailed resource monitoring
}

// Pipeline-level email notifications (one email per pipeline run)
notification {
    enabled = true
    to = 'dpbudke@ucdavis.edu'
}